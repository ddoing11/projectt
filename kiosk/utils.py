import difflib
import re
from difflib import SequenceMatcher


def is_positive(text):
    """ê¸ì • ì‘ë‹µ ê°ì§€"""
    text = text.strip().lower()
    positive_words = ["ë„¤", "ì‘", "ì˜ˆ", "ê·¸ë˜", "ì¢‹ì•„", "ì˜¤ì¼€ì´", "ì›…", "ã…‡ã…‡", "ì¢‹ìŠµë‹ˆë‹¤", "ê·¸ë ‡ì£ ", "ë„¤ë„¤", "ì˜ˆìŠ¤", "ì˜ˆì“°", "yes", "ì‘ì‘", "ì—‰", "ê·¼ë°", "ì—", "ì´ë•Œ"]

    # ì™„ì „ ì¼ì¹˜
    if text in positive_words:
        return True

    # ë§ˆì§€ë§‰ 1~3ê¸€ìê°€ ê¸ì •ì–´ë¡œ ëë‚˜ëŠ” ê²½ìš°
    for word in positive_words:
        if text.endswith(word):
            return True

    return match_fuzzy(text, positive_words)


def is_negative(text):
    """ë¶€ì • ì‘ë‹µ ê°ì§€"""
    negative_words = ["ì•„ë‹ˆ", "ì‹«ì–´", "ì•ˆë¼", "ë…¸", "ê·¸ë§Œ", "ì•„ë‹ˆìš”", "ì•ˆí• ë˜"]
    return any(word in text for word in negative_words) or match_fuzzy(text, negative_words)


def match_fuzzy(text, candidates):
    """í¼ì§€ ë§¤ì¹­"""
    for word in candidates:
        ratio = difflib.SequenceMatcher(None, text, word).ratio()
        if ratio > 0.6:
            return True
    return False


def has_order_intent(text):
    """ì£¼ë¬¸ ì˜ë„ ê°ì§€"""
    order_keywords = ["ì£¼ì„¸ìš”", "ì£¼ë¬¸", "ë¨¹ê³ ", "ë§ˆì‹œê³ ", "ê°–ê³ ", "ì£¼ë¼", "í•˜ê³ ", "ì‹œí‚¬ê²Œ", "ì‹œí‚¤ê³ ", "ì¤˜", "í• ë˜"]
    return any(k in text for k in order_keywords)


def clean_input(text):
    """ì…ë ¥ í…ìŠ¤íŠ¸ ì •ì œ"""
    original_text = text  # ë°±ì—…
    original_cleaned = text.strip().lower()

    text = re.sub(r"[^\wê°€-í£]", "", text)
    text = text.replace(" ", "").lower()
    
    # ë¶ˆí•„ìš”í•œ ëë§ ì œê±° (ì˜ˆ: ì„ íƒí•´ì£¼ì„¸ìš”, ë§ì”€í•´ì£¼ì„¸ìš” ë“±)
    system_phrases = ["ì„ íƒí•´ì£¼ì„¸ìš”", "ë§ì”€í•´ì£¼ì„¸ìš”", "ëŒ€ë‹µí•´ì£¼ì„¸ìš”", "í•´ì£¼ì„¸ìš”"]
    for phrase in system_phrases:
        if text.endswith(phrase):
            text = text[: -len(phrase)]

    question_prefixes = [
        "ìŒì„±ìœ¼ë¡œì£¼ë¬¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ", "ìŒì„±ì£¼ë¬¸ì„ì‹œì‘í•©ë‹ˆë‹¤", "ì–´ë–¤ë©”ë‰´ë¥¼ì›í•˜ì„¸ìš”",
        "ë‹¤ì‹œë©”ë‰´ë¥¼ë§ì”€í•´ì£¼ì„¸ìš”", "ë‹¤ì‹œë§ì”€í•´ì£¼ì„¸ìš”",
        "ê°™ì€ì˜µì…˜ìœ¼ë¡œì£¼ë¬¸í• ê¹Œìš”", "ì˜µì…˜ì„ì§„í–‰í• ê¹Œìš”", "ì•„ë©”ë¦¬ì¹´ë…¸ë‹¤ì‹œì£¼ë¬¸í•˜ì‹œê² ì–´ìš”", "ì‚¬ ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "ê°™ì€ì˜µì…˜ìœ¼ë¡œì£¼ë¬¸í• ê¹Œìš”ë„¤ë˜ëŠ”ì•„ë‹ˆìš”ë¡œë§ì”€í•´ì£¼ì„¸ìš”",  # ì™„ì „í•œ ë¬¸ì¥ë„ í¬í•¨
        "ì˜µì…˜ì„ì§„í–‰í• ê¹Œìš”ë„¤ë˜ëŠ”ì•„ë‹ˆìš”ë¡œë§ì”€í•´ì£¼ì„¸ìš”", "4 ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆë‹¤ ", "ë™ì¼í•œ ì˜µì…˜ìœ¼ë¡œ í•˜ë‚˜ ë” ë‹´ì„ê¹Œìš”", 
        "ì¶”ê°€ ì£¼ë¬¸ ì—¬ë¶€ë¥¼ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”", "ë©”ë‰´ ìˆìœ¼ì‹ ê°€ìš”", "ìŒì„±ìœ¼ë¡œì£¼ë¬¸í•˜ì‹œê² ìŠµë‹ˆë‹¤", "ì°¨ ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ", 
        "ì‚¬ì¶”ê°€ì—¬ë¶€ë¥¼ë‹¤ì‹œ", "ì‚¬ì¶”ê°€ ì—¬ë¶€ë¥¼ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”", "ì‚¬ ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆë‹¤", "í° ì‚¬ì´ì¦ˆëŠ” 500ì›ì´ ì¶”ê°€ë©ë‹ˆë‹¤", 
        "2,500ì›ì…ë‹ˆë‹¤", "ì–´ë–¤ ë©”ë‰´ë¥¼ ì›í•˜ì„¸ìš”", "ê°„ë‹¨í•œ ì‹ì‚¬ ëŒ€ìš©ìœ¼ë¡œë„ ì¢‹ìŠµë‹ˆë‹¤", "í° ì‚¬ì´ì¦ˆëŠ” 500ì›ì´ ì¶”ê°€ë©ë‹ˆë‹¤", 
        "ê²°ì œë¥¼ ì§„í–‰í• ê¹Œìš”", "ê²°ì œë¥¼ ì§„í–‰í• ê¹Œìš”?", "ìˆìœ¼ì‹ ê°€ìš”"
    ]
    
    # âœ… ì‹œìŠ¤í…œ ì§ˆë¬¸ ìœ ì‚¬ ì‹œì‘ë¬¸ ì œê±°
    for _ in range(3):
        for phrase in question_prefixes:
            if text.startswith(phrase):
                print(f"ğŸ” ì‹œìŠ¤í…œ ë¬¸ì¥ ì œê±°ë¨: {phrase}")
                text = text[len(phrase):]

    # âœ… ë ë¬¸ì¥ë„ ì˜ë¼ë‚´ê¸°
    SYSTEM_SUFFIXES = [
        "ë„¤ë˜ëŠ”ì•„ë‹ˆìš”ë¡œëŒ€ë‹µí•´ì£¼ì„¸ìš”",
        "ë‹¤ì‹œë§ì”€í•´ì£¼ì„¸ìš”ë„¤",
        "ë„¤ë˜ëŠ”ì•„ë‹ˆìš”ë¡œë§ì”€í•´ì£¼ì„¸ìš”",
        "ë„¤ë˜ëŠ”ì•„ë‹ˆìš”ë¡œë‹µí•´ì£¼ì„¸ìš”"
    ]
    for suffix in SYSTEM_SUFFIXES:
        if text.endswith(suffix):
            print(f"ğŸ”š ë ë¬¸ì¥ ì œê±°ë¨: {suffix}")
            text = text[: -len(suffix)]

    # âœ… ë§Œì•½ ì œê±° í›„ ë¹„ì–´ ìˆê³ , ì›ë³¸ë„ ì‹œìŠ¤í…œ ì§ˆë¬¸ì´ë©´ ë¬´ì‹œ (ë¹ˆ í…ìŠ¤íŠ¸ ë°˜í™˜)
    if not text.strip():
        all_phrases = question_prefixes + SYSTEM_SUFFIXES
        for p in all_phrases:
            if original_cleaned.startswith(p) or original_cleaned.endswith(p):
                print(f"ğŸ›‘ ì…ë ¥ì´ ì‹œìŠ¤í…œ ë¬¸ì¥ìœ¼ë¡œë§Œ êµ¬ì„±ë¨ â†’ ë¬´ì‹œ ëŒ€ìƒ")
                return ""
        # ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ì›ë³¸ ìœ ì§€
        return original_text

    # âœ… í”í•œ íŒ¨í„´ ì •ë¦¬
    system_phrases = ["ì„ íƒí•´ì£¼ì„¸ìš”", "ë§ì”€í•´ì£¼ì„¸ìš”", "ëŒ€ë‹µí•´ì£¼ì„¸ìš”", "í•´ì£¼ì„¸ìš”"]
    for phrase in system_phrases:
        if text.endswith(phrase):
            text = text[: -len(phrase)]

    for j in ["ì„", "ë¥¼", "ì´", "ê°€", "ì€", "ëŠ”", "ì—ì„œ", "ë¡œ", "ìœ¼ë¡œ", "ë„", "ë§Œ", "ê»˜", "í•œí…Œ", "ì—ê²Œ", "ë‘", "í•˜ê³ "]:
        if text.endswith(j):
            text = text[:-len(j)]
            break
    return text


def strip_gpt_response_prefix(text, last_gpt_reply):
    """GPT ì‘ë‹µ ì ‘ë‘ì‚¬ ì œê±°"""
    if not last_gpt_reply:
        return text
    gpt_clean = clean_input(last_gpt_reply)
    text_clean = clean_input(text)

    if text_clean.startswith(gpt_clean[:20]):  # ì• 20ì ìœ ì‚¬ì„± ê²€ì‚¬
        print("ğŸ” GPT ì‘ë‹µ ì•ë¶€ë¶„ í¬í•¨ â†’ ì œê±° ì‹œë„")
        return text_clean.replace(gpt_clean, "").strip()
    return text


def fuzzy_remove_question(cleaned_text, last_question):
    """í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ ì§ˆë¬¸ ì œê±°"""
    if not last_question or len(cleaned_text) <= 2:
        return cleaned_text  # â¤ ì‘ë‹µì´ ì§§ìœ¼ë©´ ì œê±°í•˜ì§€ ì•ŠìŒ

    q_cleaned = clean_input(last_question)
    ratio = SequenceMatcher(None, cleaned_text, q_cleaned).ratio()

    if ratio > 0.85 and q_cleaned in cleaned_text:
        result = cleaned_text.replace(q_cleaned, "").strip()
        if result == "":
            # âš ï¸ ì§ˆë¬¸ë§Œ ë‚¨ì•„ ì‘ë‹µì´ ì‚¬ë¼ì§€ë©´ ì œê±°í•˜ì§€ ì•Šê³  ì›ë¬¸ ìœ ì§€
            print("âš ï¸ ì§ˆë¬¸ ì œê±° í›„ ì‘ë‹µì´ ì‚¬ë¼ì§ â†’ ì œê±°í•˜ì§€ ì•ŠìŒ")
            return cleaned_text
        print(f"ğŸ§½ ì‹œìŠ¤í…œ ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ {ratio:.2f} â†’ ì§ˆë¬¸ ì œê±°ë¨")
        return result

    return cleaned_text


def is_order_expression(text):
    """ì£¼ë¬¸ í‘œí˜„ ê°ì§€"""
    order_phrases = [
        "ì£¼ì„¸ìš”", "ì£¼ë¬¸í• ê²Œìš”", "ì‹œí‚¬ê²Œìš”", "ê°–ê³ ê°ˆê²Œìš”",
        "ë¨¹ì„ê²Œìš”", "ì‚´ê²Œìš”", "í• ê²Œìš”", "ì¤˜", "ì£¼ë¼", "ì¤„ë˜",
        "ë„í•˜ë‚˜ì£¼ì„¸ìš”", "í•˜ë‚˜ì£¼ì„¸ìš”", "ë”ì£¼ì„¸ìš”"
    ]
    
    text_clean = text.replace(" ", "").lower()
    
    for phrase in order_phrases:
        if phrase in text_clean:
            return True
        if difflib.SequenceMatcher(None, text_clean, phrase).ratio() > 0.7:
            return True
    return False


def is_repeat_order(text):
    """ë°˜ë³µ ì£¼ë¬¸ ê°ì§€"""
    repeat_keywords = [
        "ê°™ì€ê±¸ë¡œ", "ê°™ì€ê±°", "ê·¸ê±¸ë¡œ", "ê·¸ê±°", "ë°©ê¸ˆ", "ë˜í•˜ë‚˜", "í•˜ë‚˜ë”", "ë‹¤ì‹œ",
        "ê°™ì€ê±°í•˜ë‚˜ë”", "ê°™ì€ë©”ë‰´", "ì•„ê¹Œ", "í•œë²ˆë”", "ì´ì „ì£¼ë¬¸", "ì „ì—ì£¼ë¬¸í•œê±°", "ì´ì „ê³¼ê°™ì€"
    ]

    text_clean = text.replace(" ", "").lower()
    return any(k in text_clean for k in repeat_keywords)